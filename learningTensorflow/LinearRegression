import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

train_x = np.linspace(-1,1,100)
#y=2x+随机噪声
train_y = 2*train_x+np.random.randn(*train_x.shape)*0.3
#创建线性回归模型
#占位符(placeholder定义占位符)
X = tf.placeholder("float")
Y = tf.placeholder("float")
#模型参数
#W为[-1,1]的随机数，定义为权重
W = tf.Variable(tf.random_normal([1]),name="weight")
#b初始化为0，定义为误差
b = tf.Variable(tf.zeros([1]),name="bias")
#前向结构
z = tf.multiply(X,W) + b
tf.summary.histogram('z',z)
#反向传播优化
#生成值与真实值的方差
cost = tf.reduce_mean(tf.square(Y-z))
tf.summary.scalar('loss_function',cost)
#定义学习率
learning_rate = 0.01
optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)

#迭代训练模型
#初始化所有变量
init = tf.global_variables_initializer()
#定义参数
training_epochs = 20    #迭代次数
display_step = 2
#生成saver
saver = tf.train.Saver()
savedir = "log/"

#plotdata = {"batchsize":[],"loss":[]}
def moving_average(a,w=10):
    if len(a) < w:
        return a[:]
    return [val if idx < w else sum(a[(idx-w):idx])/w for idx,val in enumerate(a)]

#启动训练session
with tf.Session() as sess:
    sess.run(init)
    #创建可视化
    merged_summary_op = tf.summary.merge_all()
    summary_writer = tf.summary.FileWriter('log/mnist_with_summaries',sess.graph)

    plotdata = {"batchsize":[],"loss":[]}
    #向模型输入数据
    for epoch in range(training_epochs):
        for (x,y) in zip(train_x,train_y):
            sess.run(optimizer,feed_dict={X:x,Y:y})

            #生成summary
            summary_str = sess.run(merged_summary_op,feed_dict={X:x,Y:y})
            summary_writer.add_summary(summary_str,epoch)


            #显示训练中的详细信息
            if epoch % display_step == 0:
                loss = sess.run(cost,feed_dict={X:train_x,Y:train_y})
                print ("Epoch:",epoch+1,"cost=",loss,"W=",sess.run(W),"b=",sess.run(b))
                if not(loss == "NA"):
                    plotdata["batchsize"].append(epoch)
                    plotdata["loss"].append(loss)
        print("finished")
        #保存模型
        saver.save(sess,savedir+"linermodel.cpkt")
        print("cost=",sess.run(cost,feed_dict={X:train_x,Y:train_y}),"W=",sess.run(W),"b=",sess.run(b))
    #模型可视化
    plt.plot(train_x,train_y,'ro',label='Original data')
    plt.plot(train_x,sess.run(W)*train_x+sess.run(b),label='Fittedline')
    plt.legend()
    plt.show()

    plotdata["avgloss"] = moving_average(plotdata["loss"])
    plt.figure(1)
    plt.subplot(211)
    plt.plot(plotdata["batchsize"],plotdata["avgloss"],"b--")
    plt.xlabel('Minibatch number')
    plt.ylabel('Loss')
    plt.title('Minbatch run vs. Training loss')

    plt.show()

    #使用模型
    print("x=0.2.z=",sess.run(z,feed_dict={X:0.2}))

    with tf.Session() as sess2:
        sess2.run(tf.global_variables_initializer())
        #载入模型
        saver.restore(sess2,savedir+"linermodel.cpkt")
        #print("x=0.2,z=",sess2.run(z,feed_dict={X:0.2}))






